{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TimeDependentGlow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "889a3516f9124829baef79ecbabdb0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec8fc450aa5941e0a707f2c8f1b0041c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_374e40ad8f474ce5b2e574b01b71d3da",
              "IPY_MODEL_86050815b7004d948dd62f6e06ea5865"
            ]
          }
        },
        "ec8fc450aa5941e0a707f2c8f1b0041c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "374e40ad8f474ce5b2e574b01b71d3da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2fbad8ffc59b400ea9161559071e3564",
            "_dom_classes": [],
            "description": "Batch:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 281,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fcf8c4d8880d44afb069a91a6745642b"
          }
        },
        "86050815b7004d948dd62f6e06ea5865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_022662d5a5c04232aa56ec900e72fecb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/281 [00:19&lt;1:07:59, 14.57s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_374c59e73f084118873d8e1ae10e33f8"
          }
        },
        "2fbad8ffc59b400ea9161559071e3564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fcf8c4d8880d44afb069a91a6745642b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "022662d5a5c04232aa56ec900e72fecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "374c59e73f084118873d8e1ae10e33f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq-NaaYq0YwA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92fb625f-ef2d-4d64-f4c6-c51554ff2957"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCNySW_o0dNj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "b493fcf9-752f-4085-b147-0eb744c7d4c8"
      },
      "source": [
        "!if [ -d deepflows ]; then rm -Rf deepflows; fi\n",
        "!git clone https://github.com/CDGlissov/recurrent-flows-msc.git deepflows\n",
        "!pip install \"./deepflows\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deepflows'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 167 (delta 29), reused 0 (delta 0), pack-reused 112\u001b[K\n",
            "Receiving objects: 100% (167/167), 1.50 MiB | 8.46 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n",
            "Processing ./deepflows\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from recurrent-flows-msc==0.1.0) (1.18.5)\n",
            "Building wheels for collected packages: recurrent-flows-msc\n",
            "  Building wheel for recurrent-flows-msc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for recurrent-flows-msc: filename=recurrent_flows_msc-0.1.0-cp36-none-any.whl size=1121 sha256=6f0a03bab919b4b554f2310768bcb9258ed84d39313ad653f07553b9787b4fcc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sgaqt7fd/wheels/f0/5a/77/8518120597d432632c6abe1aa892d29d8c308fccf620551d65\n",
            "Successfully built recurrent-flows-msc\n",
            "Installing collected packages: recurrent-flows-msc\n",
            "Successfully installed recurrent-flows-msc-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2jfiG7H0fud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "386e0509-912c-460f-ad2a-c139547a0f16"
      },
      "source": [
        "from deepflows.data_generators import celeba\n",
        "from deepflows import utils\n",
        "import numpy as np\n",
        "import pickle\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import IPython\n",
        "import os\n",
        "import pandas as pd\n",
        "from scipy import linalg as la\n",
        "from math import log, pi, exp\n",
        "from deepflows.data_generators import stochasticShapes\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "device = utils.set_gpu(True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Note: GPU is not available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugo_PLtc0iXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "8559cd11-fecd-433d-ebc4-6478e0556f9d"
      },
      "source": [
        "batch_size = 32\n",
        "dataset = stochasticShapes.MovingShapes(root_dir = \"/content/gdrive/My Drive/movingShapes.h5\")\n",
        "trainset, valset = torch.utils.data.random_split(dataset, [9000, 1000])\n",
        "\n",
        "train_loader_t = DataLoader(valset, batch_size=10, shuffle=True)\n",
        "\n",
        "x_plot = next(iter(train_loader_t))[0].permute(0,3,2,1)\n",
        "\n",
        "fig, ax = plt.subplots(1, 5, figsize = (20,5))\n",
        "ax[0].imshow(x_plot[0])\n",
        "ax[1].imshow(x_plot[1])\n",
        "ax[2].imshow(x_plot[2])\n",
        "ax[3].imshow(x_plot[3])\n",
        "ax[4].imshow(x_plot[4])\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABH4AAADgCAYAAAB1lqE5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVDklEQVR4nO3db6itaXnf8d/VOTOJRBvHmEyHmbGaRAgiZqSDNURatbVMfDOmiERomBLp5EUtBvqikkJNWwoJtEoJ/cOkDmcoVmvVRCml7USGWigYj2aio0OiCUpmepyDGIm2xb9XX+w19Tg9z9n/nrX3ve71+cDm7H2ftZ/nfpj1dfTyWWtVdwcAAACA+fyZ894AAAAAANth8AMAAAAwKYMfAAAAgEkZ/AAAAABMyuAHAAAAYFIGPwAAAACTunCaX66qu5P88yQ3JPk33f2rhzzeZ8ez17q7zuI82oTj0SaMSZswJm3CmJbarO6TtVFVNyT5gySvSfJ4ko8leWN3f+Y6vyNE9tpZ/EtSm3B82oQxaRPGpE0Y01Kbp3mp18uSfK67/6i7v5HkPUnuOcXxgHVoE8akTRiTNmFM2oSVnGbwc1uSP77q58c3a9+jqu6rqktVdekU5wKOTpswJm3CmLQJY9ImrORU7/FzFN19f5L7E7fewUi0CWPSJoxJmzAmbcLhTnPHzxNJ7rjq59s3a8D50iaMSZswJm3CmLQJKznN4OdjSV5YVS+oqpuS/FySD62zLeAUtAlj0iaMSZswJm3CSk78Uq/u/lZVvTnJf8nBx+s90N2fXm1nwIloE8akTRiTNmFM2oT1nPjj3E90Mq+5ZM+dxUdfnoQ22XfahDFpE8akTRjTNj7OHQAAAICBGfwAAAAATMrgBwAAAGBSBj8AAAAAkzL4AQAAAJiUwQ8AAADApAx+AAAAACZl8AMAAAAwKYMfAAAAgEkZ/AAAAABMyuAHAAAAYFIGPwAAAACTMvgBAAAAmJTBDwAAAMCkDH4AAAAAJmXwAwAAADApgx8AAACASRn8AAAAAEzK4AcAAABgUgY/AAAAAJMy+AEAAACY1IXT/HJVfT7JV5N8O8m3uvuuNTYFnI42YUzahDFpE8akTVjHqQY/G6/q7i+tcBxgXdqEMWkTxqRNGJM24ZS81AsAAABgUqcd/HSS/1pVH6+q+671gKq6r6ouVdWlU54LODptwpi0CWPSJoxJm7CC6u6T/3LVbd39RFX9SJKHkvyd7v7IdR5/8pPBBLq7zuI82oTj0SaMSZswJm3CmJbaPNUdP939xObPK0l+M8nLTnM8YB3ahDFpE8akTRiTNmEdJx78VNUPVNWznvo+yV9L8uhaGwNORpswJm3CmLQJY9ImrOc0n+p1S5LfrKqnjvPvuvs/r7Ir4DS0CWPSJoxJmzAmbcJKTvUeP8c+mddcsufO6vXQx6VN9p02YUzahDFpE8a0lff4AQAAAGBcBj8AAAAAkzL4AQAAAJiUwQ8AAADApAx+AAAAACZl8AMAAAAwKYMfAAAAgEkZ/AAAAABMyuAHAAAAYFIGPwAAAACTMvgBAAAAmJTBDwAAAMCkDH4AAAAAJmXwAwAAADApgx8AAACASRn8AAAAAEzK4AcAAABgUgY/AAAAAJMy+AEAAACYlMEPAAAAwKQMfgAAAAAmdejgp6oeqKorVfXoVWvPqaqHquqzmz9v3u42gafTJoxJmzAmbcKYtAnbd5Q7fi4muftpa29N8uHufmGSD29+Bs7WxWgTRnQx2oQRXYw2YUQXo03YqkMHP939kSRfftryPUke3Hz/YJLXrbwv4BDahDFpE8akTRiTNmH7TvoeP7d09+XN919McstK+wFOR5swJm3CmLQJY9ImrOjCaQ/Q3V1VvfT3VXVfkvtOex7geLQJY9ImjEmbMCZtwumd9I6fJ6vq1iTZ/Hll6YHdfX9339Xdd53wXMDRaRPGpE0YkzZhTNqEFZ108POhJPduvr83yQfX2Q5wStqEMWkTxqRNGJM2YUXVvXjX3MEDqt6d5JVJnpvkySRvS/JbSd6b5HlJvpDkDd399Dfkutaxrn8ymFx311rH0iasR5swJm3CmLQJY1pq89DBz5qEyL5b81+Sa9Im+06bMCZtwpi0CWNaavOkL/UCAAAAYHAGPwAAAACTMvgBAAAAmJTBDwAAAMCkDH4AAAAAJmXwAwAAADApgx8AAACASRn8AAAAAEzK4AcAAABgUgY/AAAAAJMy+AEAAACYlMEPAAAAwKQMfgAAAAAmZfADAAAAMCmDHwAAAIBJXTjvDbAFt57gdy6vvgsAAADgnLnjBwAAAGBSBj8AAAAAkzL4AQAAAJiUwQ8AAADApAx+AAAAACZ16OCnqh6oqitV9ehVa79SVU9U1SObr9dud5scy8+c4Iudo00YkzZhTNqEMWkTtu8od/xcTHL3Ndbf0d13br7+07rbAo7gYrQJI7oYbcKILkabMKKL0SZs1aGDn+7+SJIvn8FegGPQJoxJmzAmbcKYtAnbd5r3+HlzVX1yc2vezavtCDgtbcKYtAlj0iaMSZuwkpMOfv5Vkh9LcmeSy0n+2dIDq+q+qrpUVZdOeC7g6LQJY9ImjEmbMCZtwoqquw9/UNXzk/zH7n7xcf7uGo89/GSc3i+c4HceWH0XXEN315rH0yasQ5swJm3CmLQJY1pq88JJDlZVt3b35c2PP5vk0es9ni1Z+o++5614LP9kd4o2YUzahDFpE8akTVjXoYOfqnp3klcmeW5VPZ7kbUleWVV3Jukkn0/yi1vcI3AN2oQxaRPGpE0YkzZh+470Uq/VTubWu3Ut3aXz+hMc630L62brq1r7tti1aJN9p00YkzZhTNqEMS21eZpP9QIAAABgYAY/AAAAAJMy+AEAAACYlMEPAAAAwKRO9HHunLEbF9Zfs+I5lo71+wvr31zx3AAAAMBWuOMHAAAAYFIGPwAAAACTMvgBAAAAmJTBDwAAAMCkDH4AAAAAJuVTvXbBzQvrnzjHc185g3MDx/eshfUfXFh/fFsbAQAARuCOHwAAAIBJGfwAAAAATMrgBwAAAGBSBj8AAAAAkzL4AQAAAJiUT/XaBUufoOWTtYCn+ysL6z+ysP4bC+u9wl4AAIBz544fAAAAgEkZ/AAAAABMyuAHAAAAYFIGPwAAAACTOnTwU1V3VNXDVfWZqvp0Vb1ls/6cqnqoqj67+fPm7W8XeIo2YUzahDFpE8akTdi+6r7+R7dU1a1Jbu3uT1TVs5J8PMnrkvzNJF/u7l+tqrcmubm7/94hx/I5Mey17q61jqXNPXfbwvrfOuZxfmth/ZFjHmfHaRPGpE0YkzZhTEttHnrHT3df7u5PbL7/apLHcvA/Oe5J8uDmYQ/mIE7gjGgTxqRNGJM2YUzahO071nv8VNXzk7w0yUeT3NLdlzd/9cUkt6y6M+DItAlj0iaMSZswJm3Cdlw46gOr6plJ3p/kl7r7T6u+ewdRd/fSbXVVdV+S+067UeDatAlj0iaMSZswJm3C9hzpjp+qujEHEb6ruz+wWX5y83rMp16XeeVav9vd93f3Xd191xobBr5LmzAmbcKYtAlj0iZs11E+1auSvDPJY9399qv+6kNJ7t18f2+SD66/PWCJNmFM2oQxaRPGpE3YvqN8qtcrkvz3JJ9K8p3N8i/n4HWX703yvCRfSPKG7v7yIcfyLuvstZU/AUGb+2DpGfOmhfXbj3n8ry2s//rC+tePefwdoU0YkzZhTNqEMS21eejgZ01CZN+t+S/JNWlzYAY/Z0KbMCZtwpi0CWM68ce5AwAAALCbDH4AAAAAJmXwAwAAADApgx8AAACASV047w0AcB03L6z/z2OuH9efW1j/wkrHB9a19N/obllYf2JbGwEARuOOHwAAAIBJGfwAAAAATMrgBwAAAGBSBj8AAAAAkzL4AQAAAJhUdffZnazq7E4GA+ruOu89XIs22XfaZOf9pYX1Fy+s/+uF9e+ssJcVaRPGpE0Y01Kb7vgBAAAAmJTBDwAAAMCkDH4AAAAAJmXwAwAAADApgx8AAACASV047w0AAHBEf3Zh/RUL6zctrP+FhfWPHW87AMD43PEDAAAAMCmDHwAAAIBJGfwAAAAATMrgBwAAAGBSBj8AAAAAkzp08FNVd1TVw1X1mar6dFW9ZbP+K1X1RFU9svl67fa3CzxFmzAmbbJVf3Xh66aFryWvWvh6xsLXBLQJY9ImbF919/UfUHVrklu7+xNV9awkH0/yuiRvSPK17v6nRz5Z1fVPBpPr7lrrWNqE9WiTnfHXF9Zfcszj/O+F9V9fWP8/xzz+SrQJY9ImjGmpzQtH+MXLSS5vvv9qVT2W5LZ1twcclzZhTNqEMWkTxqRN2L5jvcdPVT0/yUuTfHSz9Oaq+mRVPVBVNy/8zn1VdamqLp1qp8AibcKYtAlj0iaMSZuwHYe+1Ov/PbDqmUn+W5J/0t0fqKpbknwpSSf5xzm4Pe8XDjmGW+/Ya2veFvsUbcLpaZOd4aVep6ZNOD1twpiW2jzSHT9VdWOS9yd5V3d/YHPAJ7v72939nSS/keRla20WOBptwpi0CWPSJoxJm7Bdh77HT1VVkncmeay7337V+q2b12Mmyc8meXQ7WwSuRZswJm2yih9YWL9hYf0zK533+Qvrj610/HOkTfbKLQvrT57pLo5Em7B9hw5+kvx0kp9P8qmqemSz9stJ3lhVd+bg1rvPJ/nFrewQWKJNGJM2YUzahDFpE7bsyO/xs8rJvOaSPbeN10OvQZvsO20ynKU7fl67sL7WM/hTC+vndMePNuGEtnzHjzZhTKd6jx8AAAAAdo/BDwAAAMCkDH4AAAAAJuU9fuAMeT00jEmbMCZtwiFevLD+qoX1f7mw/u3jnVabMCbv8QMAAACwZwx+AAAAACZl8AMAAAAwKYMfAAAAgEkZ/AAAAABM6sJ5bwAAAIDruHFh/TUL6z+4sP4XF9b/x/G2A+wWd/wAAAAATMrgBwAAAGBSBj8AAAAAkzL4AQAAAJiUwQ8AAADApHyqFwAAwMh+emF96dO7lvzlhfXfW1j/X8c8PjAkd/wAAAAATMrgBwAAAGBSBj8AAAAAkzL4AQAAAJiUwQ8AAADApA79VK+q+v4kH0nyfZvHv6+731ZVL0jyniQ/lOTjSX6+u7+xzc0C36VNGJM2YUzaZCfctLB+x8L6F1Y674sW1j+20vGvQ5uwfUe54+frSV7d3T+Z5M4kd1fVy5P8WpJ3dPePJ/mTJG/a3jaBa9AmjEmbMCZtwpi0CVt26OCnD3xt8+ONm69O8uok79usP5jkdVvZIXBN2oQxaRPGpE0YkzZh+470Hj9VdUNVPZLkSpKHkvxhkq9097c2D3k8yW0Lv3tfVV2qqktrbBj4Lm3CmLQJY9ImjEmbsF1HGvx097e7+84ktyd5WZKfOOoJuvv+7r6ru+864R6BBdqEMWkTxqRNGJM2YbuO9ale3f2VJA8n+akkz66qp94c+vYkT6y8N+CItAlj0iaMSZswJm3CdhzlU71+OMk3u/srVfWMJK/JwRttPZzk9Tl4p/V7k3xwmxsFvpc2YUzahDFpk52w9JlV//ZMd3GmtAkncK0XPl5Zfnh193WPV1UvycGbad2QgzuE3tvd/6iqfjQHET4nye8m+Rvd/fVDjnX9k8HkurvWOpY2YT3ahDFpE8akTThnC4Of/sa12zx08LMmIbLv1vyX5Jq0yb7TJoxJmzAmbcI5O+bg51jv8QMAAADA7jD4AQAAAJiUwQ8AAADApA79VK+VfSnJFzbfP3fz875wvXM7yvX++bPYyAlpc3+43v+fNsfkeuemzd3leuemzd3leuf2vdf7xDUfs9jmmb658/ecuOpSd991Lic/B653bjNd70zXchSud24zXe9M13IUrnduM13vTNdyFK53bjNd70zXchSud26nvV4v9QIAAACYlMEPAAAAwKTOc/Bz/zme+zy43rnNdL0zXctRuN65zXS9M13LUbjeuc10vTNdy1G43rnNdL0zXctRuN65nep6z+09fgAAAADYLi/1AgAAAJiUwQ8AAADApM588FNVd1fV71fV56rqrWd9/rNQVQ9U1ZWqevSqtedU1UNV9dnNnzef5x7XVFV3VNXDVfWZqvp0Vb1lsz7lNVfV91fV71TV722u9x9u1l9QVR/dPLf/fVXddN57PQ5tzvU8TbSpzd2xT23uW5eJNneZNue93kSbu2qfukz2r81tdXmmg5+quiHJv0jyM0lelOSNVfWis9zDGbmY5O6nrb01yYe7+4VJPrz5eRbfSvJ3u/tFSV6e5G9v/rnOes1fT/Lq7v7JJHcmubuqXp7k15K8o7t/PMmfJHnTOe7xWLQ55fM00aY2d8fF7E+b+9Zlos1ddjHanPV6E23uqovZny6T/WtzK12e9R0/L0vyue7+o+7+RpL3JLnnjPewdd39kSRfftryPUke3Hz/YJLXnemmtqi7L3f3JzbffzXJY0luy6TX3Ae+tvnxxs1XJ3l1kvdt1nfterV5YNf+uV2XNrW5K/apzX3rMtHmLtOmNrN71zx9m/vUZbJ/bW6ry7Me/NyW5I+v+vnxzdo+uKW7L2++/2KSW85zM9tSVc9P8tIkH83E11xVN1TVI0muJHkoyR8m+Up3f2vzkF17bmvzwFTP06tpU5s7aNrn6VP2pctEm5OZ+rmaaDPa3EVTP0+fsi9tbqNLb+58Drq7czC1m0pVPTPJ+5P8Unf/6dV/N9s1d/e3u/vOJLfn4P9Z+Ilz3hIrmO15+hRtsutme54m+9Vlos1Zzfhc1aY2d92Mz9Nkv9rcRpdnPfh5IskdV/18+2ZtHzxZVbcmyebPK+e8n1VV1Y05CPFd3f2BzfLU15wk3f2VJA8n+akkz66qC5u/2rXntjYz5/NUm9rcYdM+T/e1y0Sbk5j2uapNbe6wqZ+n+9rmml2e9eDnY0leuHlH6puS/FySD53xHs7Lh5Lcu/n+3iQfPMe9rKqqKsk7kzzW3W+/6q+mvOaq+uGqevbm+2ckeU0OXmv6cJLXbx62a9erzQO79s/turSpzR036/N0r7pMtDmhKZ+r2tTmjpv5ebpXbW6ty+4+068kr03yBzl4ndrfP+vzn9E1vjvJ5STfzMHr796U5Idy8G7jn03y20mec977XPF6X5GDW+s+meSRzddrZ73mJC9J8rub6300yT/YrP9okt9J8rkk/yHJ9533Xo95Xdqc6Hm6uV5ttjZ34Wuf2ty3LjfXrM0d/dKmNrU53tc+dbm53r1qc1td1uYgAAAAAEzGmzsDAAAATMrgBwAAAGBSBj8AAAAAkzL4AQAAAJiUwQ8AAADApAx+AAAAACZl8AMAAAAwqf8LEB7v28Rgxe0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9kuezvT0lIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logabs = lambda x: torch.log(torch.abs(x))\n",
        "\n",
        "\n",
        "class ConditionNet(nn.Module):\n",
        "    def __init__(self, in_channels, output_channels, height, width, hid_dim = 32):\n",
        "        \"\"\"\n",
        "        A condition net. It takes in and out channels as input.\n",
        "        Output is x, it is usually used to estimate the parameters for the affine transformation, hence\n",
        "        the output dimensions are usually multiplied by 2, as we need two parameters.\n",
        "        \"\"\"\n",
        "        super(ConditionNet, self).__init__()\n",
        "        layers = [WeightNormConv2d(in_channels, in_channels, (2, 2), stride=2, padding= 0 ),\n",
        "                  nn.ReLU(),\n",
        "                  WeightNormConv2d(in_channels, in_channels, (2, 2), stride=2, padding=0),\n",
        "                  nn.ReLU(),\n",
        "                  WeightNormConv2d(in_channels, in_channels, (2, 2), stride=2, padding=0),\n",
        "                  nn.ReLU()]\n",
        "        h, w = utils.get_layer_size([height, width], kernels=[2, 2, 2], paddings=[0, 0, 0], strides=[2, 2, 2],\n",
        "                                    dilations=[1, 1, 1])\n",
        "        self.net = nn.Sequential(*layers)\n",
        "        layers_flatten = [nn.Linear(h * w * (in_channels), 32), nn.ReLU(), nn.Linear(32, 32), nn.ReLU(),\n",
        "                          nn.Linear(32, output_channels), nn.Tanh()]\n",
        "\n",
        "        self.net_flatten = nn.Sequential(*layers_flatten)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        x = self.net(x)\n",
        "        x = x.view(batch_size, -1)\n",
        "        x = self.net_flatten(x)\n",
        "        x = x.view(batch_size, -1, 1, 1)\n",
        "        return x\n",
        "\n",
        "class WeightNormConv2d(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, kernel_size, stride=1, padding=0,\n",
        "                 bias=True):\n",
        "        super(WeightNormConv2d, self).__init__()\n",
        "        self.conv = nn.utils.weight_norm(\n",
        "            nn.Conv2d(in_dim, out_dim, kernel_size,\n",
        "                      stride=stride, padding=padding, bias=bias))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            WeightNormConv2d(dim, dim, (1, 1), stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            WeightNormConv2d(dim, dim, (3, 3), stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            WeightNormConv2d(dim, dim, (1, 1), stride=1, padding=0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "\n",
        "class SimpleResnet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, n_filters=64, n_blocks=4):\n",
        "        super(SimpleResnet, self).__init__()\n",
        "        layers = [WeightNormConv2d(in_channels, n_filters, (3, 3), stride=1, padding=1),\n",
        "                  nn.ReLU()]\n",
        "        for _ in range(n_blocks):\n",
        "            layers.append(ResnetBlock(n_filters))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(WeightNormConv2d(n_filters, out_channels, (3, 3), stride=1, padding=1))\n",
        "        self.resnet = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "class ConditionalInvConv(nn.Module):\n",
        "    def __init__(self, x_channels, c_channels, height, width):\n",
        "        \"\"\"\n",
        "        Conditional 1x1 convolution\n",
        "        Takes in the argument x, and the conditional.\n",
        "        Convolution W is found by NN.\n",
        "        \"\"\"\n",
        "        super(ConditionalInvConv, self).__init__()\n",
        "        self.x_channels = x_channels\n",
        "        self.ConditionalNet = ConditionNet(in_channels = c_channels, \n",
        "                                           output_channels= x_channels * x_channels, \n",
        "                                           height = height, width = width)\n",
        "    \n",
        "    def forward(self, x, condition, reverse=False):\n",
        "        B, C, H, Wi = x.size()\n",
        "        W = self.ConditionalNet(condition)\n",
        "        W = W.view(B, self.x_channels, self.x_channels)\n",
        "        logdet = torch.slogdet(W)[1]\n",
        "        W = W.view(B, self.x_channels, self.x_channels, 1, 1)\n",
        "        x = x.reshape(1, B * C, H, Wi)  \n",
        "        B_k, C_i_k, C_o_k, H_k, W_k = W.size()\n",
        "        W = W.view(B_k * C_i_k, C_o_k, H_k, W_k)\n",
        "\n",
        "        if reverse:\n",
        "            W = W.view(B, self.x_channels, self.x_channels)\n",
        "            W = torch.inverse(W.double()).float().view(B, self.x_channels, self.x_channels, 1, 1)\n",
        "            W = W.reshape(B_k * C_i_k, C_o_k, H_k, W_k)\n",
        "            out = F.conv2d(x, W, groups=B)\n",
        "            out = out.view(B, C, H, Wi)\n",
        "        else:\n",
        "            out = F.conv2d(x, W, groups=B)\n",
        "            out = out.view(B, C, H, Wi)\n",
        "        \n",
        "        return out, logdet.view(B, 1, 1, 1)\n",
        "\n",
        "\n",
        "class ConditionalActNorm(nn.Module):\n",
        "    def __init__(self, x_channels, c_channels, height, width):\n",
        "        \"\"\"\n",
        "        Applied conditional ActNorm, finds the conditional shift. From the condition.\n",
        "        \"\"\"\n",
        "        super(ConditionalActNorm, self).__init__()\n",
        "        self.c_channels = c_channels\n",
        "        self.x_channels = x_channels\n",
        "        self.ConditionalNet = ConditionNet(in_channels = self.c_channels, output_channels = 2 * self.x_channels, \n",
        "                                           height = height, width = width)\n",
        "\n",
        "    def forward(self, x, condition, reverse=False):\n",
        "        output = self.ConditionalNet(condition)\n",
        "        log_scale, shift = output.split(output.shape[1] // 2, dim=1)\n",
        "        if reverse:\n",
        "            return (x - shift) * torch.exp(-log_scale), log_scale\n",
        "        else:\n",
        "            return x * torch.exp(log_scale) + shift, log_scale\n",
        "\n",
        "# See this https://github.com/ndrplz/ConvLSTM_pytorch and https://www.quora.com/What-is-the-difference-between-ConvLSTM-and-CNN-LSTM\n",
        "class ConvLSTMLayer(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size, bias, dropout = 0):\n",
        "        super(ConvLSTMLayer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dropout = dropout\n",
        "        self.padding = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
        "        self.bias = bias\n",
        "        self.conv = nn.Conv2d(in_channels = self.input_dim + self.hidden_dim,\n",
        "                              out_channels = 4 * self.hidden_dim,\n",
        "                              kernel_size = self.kernel_size,\n",
        "                              padding = self.padding,\n",
        "                              bias = self.bias)\n",
        "        self.dropout = nn.Dropout2d(p = dropout)\n",
        "\n",
        "    def forward(self, input_tensor, cur_state):\n",
        "        h_cur, c_cur = cur_state\n",
        "\n",
        "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
        "        combined_conv = self.conv(combined)\n",
        "        combined_conv = self.dropout(combined_conv)\n",
        "\n",
        "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
        "        i = torch.sigmoid(cc_i)\n",
        "        f = torch.sigmoid(cc_f)\n",
        "        o = torch.sigmoid(cc_o)\n",
        "        g = torch.tanh(cc_g)\n",
        "        c_next = f * c_cur + i * g\n",
        "        h_next = o * torch.tanh(c_next)\n",
        "\n",
        "        return h_next, c_next\n",
        "\n",
        "    def init_states(self, batch_size, image_size):\n",
        "        height, width = image_size\n",
        "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
        "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
        "        \n",
        "class ConvLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True, dropout = 0):\n",
        "        super(ConvLSTM, self).__init__()\n",
        "        \n",
        "        self.LSTMlayer = ConvLSTMLayer(input_dim=input_dim,\n",
        "                                          hidden_dim=hidden_dim,\n",
        "                                          kernel_size=kernel_size,\n",
        "                                          bias=bias, dropout=dropout)\n",
        "    def forward(self, x, hidden_states):\n",
        "        ht, ct = hidden_states\n",
        "        b, seq_len, channel, h, w = x.size()\n",
        "        #print(seq_len)\n",
        "        for t in range(seq_len):\n",
        "            ht, ct = self.LSTMlayer(input_tensor=x[:, t, :, :, :],\n",
        "                                              cur_state=[ht, ct])\n",
        "        return ht, ct\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cxx-uqj04hZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class ConditionalAffineCheckerboardTransform(nn.Module):\n",
        "    def __init__(self, type, x_channels, c_channels):\n",
        "        super(ConditionalAffineCheckerboardTransform, self).__init__()\n",
        "        \n",
        "        self.mask = self.build_mask(type=type)\n",
        "        self.scale = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
        "        self.scale_shift = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
        "\n",
        "        self.x_channels = x_channels\n",
        "        self.c_channels = c_channels\n",
        "        self.resnet = SimpleResnet(in_channels=self.x_channels + self.c_channels,\n",
        "                                   out_channels=self.x_channels * 2, n_blocks = 4)\n",
        "\n",
        "    def build_mask(self, type=1.0):\n",
        "        # if type == 1.0, the top left corner will be 1.0\n",
        "        # if type == 0.0, the top left corner will be 0.0\n",
        "        mask = np.arange(32).reshape(-1, 1) + np.arange(32)\n",
        "        mask = np.mod(type + mask, 2)\n",
        "        mask = mask.reshape(-1, 1, 32, 32)\n",
        "        return torch.tensor(mask.astype('float32')).to(device)\n",
        "\n",
        "    def forward(self, x, condition, reverse=False):\n",
        "        # returns transform(x), log_det\n",
        "        batch_size, n_channels, _, _ = x.shape\n",
        "        mask = self.mask.repeat(batch_size, 1, 1, 1)\n",
        "        x_ = x * mask\n",
        "\n",
        "        # Takes the concatinating condition on the x.\n",
        "        log_s, t = self.resnet(torch.cat((x_, condition), dim=1)).split(n_channels, dim=1)\n",
        "        log_s = self.scale * torch.tanh(log_s) + self.scale_shift\n",
        "        t = t * (1.0 - mask)\n",
        "        log_s = log_s * (1.0 - mask)\n",
        "\n",
        "        if reverse:\n",
        "            x = (x - t) * torch.exp(-log_s)\n",
        "        else:\n",
        "            x = x * torch.exp(log_s) + t\n",
        "        return x, log_s\n",
        "\n",
        "#change all these channels\n",
        "class ConditionalAffineChannelTransform(nn.Module):\n",
        "    def __init__(self, modify_top, x_channels, c_channels):\n",
        "        super(ConditionalAffineChannelTransform, self).__init__()\n",
        "        self.modify_top = modify_top\n",
        "        self.x_channels = x_channels\n",
        "        self.c_channels = c_channels\n",
        "        self.scale = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
        "        self.scale_shift = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
        "\n",
        "        self.resnet = SimpleResnet(in_channels=self.x_channels // 2 + self.c_channels,\n",
        "                                   out_channels=self.x_channels, n_blocks = 4)\n",
        "\n",
        "    def forward(self, x, condition, reverse=False):\n",
        "        if self.modify_top:\n",
        "            on, off = x.split(self.x_channels // 2, dim=1)\n",
        "        else:\n",
        "            off, on = x.split(self.x_channels // 2, dim=1)\n",
        "        log_s, t = self.resnet(torch.cat((off, condition), dim=1)).split(self.x_channels // 2, dim=1)\n",
        "        log_s = self.scale * torch.tanh(log_s) + self.scale_shift\n",
        "        if reverse:\n",
        "            on = (on - t) * torch.exp(-log_s)\n",
        "        else:\n",
        "            on = on * torch.exp(log_s) + t\n",
        "\n",
        "        if self.modify_top:\n",
        "            return torch.cat([on, off], dim=1), torch.cat([log_s, torch.zeros_like(log_s)], dim=1)\n",
        "        else:\n",
        "            return torch.cat([off, on], dim=1), torch.cat([torch.zeros_like(log_s), log_s], dim=1)\n",
        "\n",
        "class GlowConditional(nn.Module):\n",
        "    def __init__(self, x_dims, c_channels):\n",
        "        super(GlowConditional, self).__init__()\n",
        "\n",
        "        self.prior = torch.distributions.Normal(torch.tensor(0.).to(device), torch.tensor(1.).to(device))\n",
        "        self.c_channels = c_channels\n",
        "        self.features_channels = 16\n",
        "        self.x_channels, self.height, self.width = x_dims\n",
        "        \n",
        "        self.counter = 0\n",
        "        self.ht = nn.Parameter(torch.zeros(batch_size, self.features_channels, 32, 32, device=device))\n",
        "        self.ct = nn.Parameter(torch.zeros(batch_size, self.features_channels, 32, 32, device=device))\n",
        "\n",
        "        ### Conditional feature extractor.\n",
        "        self.FeatureExtractorNet = ConvLSTM(input_dim = 3, hidden_dim = self.features_channels, kernel_size = (3,3)).to(device)\n",
        "\n",
        "        self.checker_transforms1 = nn.ModuleList([\n",
        "            ConditionalAffineCheckerboardTransform(type=1.0, x_channels=self.x_channels, c_channels=self.features_channels),\n",
        "            ConditionalActNorm(x_channels=self.x_channels, c_channels=self.features_channels, height = self.height, width = self.width),\n",
        "            ConditionalAffineCheckerboardTransform(type=0., x_channels=self.x_channels, c_channels=self.features_channels),\n",
        "            ConditionalActNorm(x_channels=self.x_channels, c_channels=self.features_channels, height = self.height, width = self.width),\n",
        "            ConditionalAffineCheckerboardTransform(type=1.0, x_channels=self.x_channels, c_channels=self.features_channels),\n",
        "            ConditionalActNorm(x_channels=self.x_channels, c_channels=self.features_channels, height = self.height, width = self.width),\n",
        "            ConditionalAffineCheckerboardTransform(type=0., x_channels=self.x_channels, c_channels=self.features_channels)\n",
        "        ])\n",
        "        \n",
        "        # Here it is squeezed so the channels is *4 \n",
        "        self.channel_transforms = nn.ModuleList([\n",
        "            ConditionalInvConv(x_channels=self.x_channels * 4, c_channels=self.features_channels * 4, height = self.height // 2, width = self.width // 2),                                      \n",
        "            ConditionalAffineChannelTransform(True, x_channels=self.x_channels * 4, c_channels=self.features_channels * 4),\n",
        "            ConditionalActNorm(x_channels=self.x_channels * 4, c_channels=self.features_channels * 4, height = self.height // 2, width = self.width // 2),\n",
        "            ConditionalAffineChannelTransform(False, x_channels=self.x_channels * 4, c_channels=self.features_channels * 4),\n",
        "            ConditionalActNorm(x_channels=self.x_channels * 4, c_channels=self.features_channels * 4, height = self.height // 2, width = self.width // 2),\n",
        "            ConditionalAffineChannelTransform(True, x_channels=self.x_channels * 4, c_channels=self.features_channels * 4),\n",
        "        ])\n",
        "        \n",
        "        self.checker_transforms2 = nn.ModuleList([\n",
        "            ConditionalInvConv(x_channels=self.x_channels, c_channels=self.features_channels, height = self.height, width = self.width),                                        \n",
        "            ConditionalAffineCheckerboardTransform(type=1.0, x_channels=self.x_channels, c_channels=self.features_channels),\n",
        "            ConditionalActNorm(x_channels=self.x_channels, c_channels=self.features_channels, height = self.height, width = self.width),\n",
        "            ConditionalAffineCheckerboardTransform(type=0., x_channels=self.x_channels, c_channels=self.features_channels),\n",
        "            ConditionalActNorm(x_channels=self.x_channels, c_channels=self.features_channels, height = self.height, width = self.width),\n",
        "            ConditionalAffineCheckerboardTransform(type=1.0, x_channels=self.x_channels, c_channels=self.features_channels),\n",
        "        ])\n",
        "\n",
        "    def squeeze(self, x):\n",
        "        # C x H x W -> 4C x H/2 x W/2\n",
        "        [B, C, H, W] = list(x.size())\n",
        "        x = x.reshape(B, C, H // 2, 2, W // 2, 2)\n",
        "        x = x.permute(0, 1, 3, 5, 2, 4)\n",
        "        x = x.reshape(B, C * 4, H // 2, W // 2)\n",
        "        return x\n",
        "\n",
        "    def undo_squeeze(self, x):\n",
        "        #  4C x H/2 x W/2  ->  C x H x W\n",
        "        [B, C, H, W] = list(x.size())\n",
        "        x = x.reshape(B, C // 4, 2, 2, H, W)\n",
        "        x = x.permute(0, 1, 4, 2, 5, 3)\n",
        "        x = x.reshape(B, C // 4, H * 2, W * 2)\n",
        "        return x\n",
        "\n",
        "    def g(self, z, condition):\n",
        "        # z -> x (inverse of f)\n",
        "        conzf, ct = self.FeatureExtractorNet(condition.unsqueeze(dim=1), (self.ht, self.ct))\n",
        "        x = z\n",
        "        for op in reversed(self.checker_transforms2):\n",
        "            x, _ = op.forward(x, conzf, reverse=True)\n",
        "        x, conzf = self.squeeze(x), self.squeeze(conzf)\n",
        "        for op in reversed(self.channel_transforms):\n",
        "            x, _ = op.forward(x, conzf, reverse=True)\n",
        "        x, conzf= self.undo_squeeze(x), self.undo_squeeze(conzf)\n",
        "        for op in reversed(self.checker_transforms1):\n",
        "            x, _ = op.forward(x, conzf, reverse=True)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def f(self, x, condition):\n",
        "        # maps x -> z, and returns the log determinant (not reduced)\n",
        "        z = x\n",
        "        conzf, ct = self.FeatureExtractorNet(condition.unsqueeze(dim=1), (self.ht, self.ct))\n",
        "        z, log_det = z, torch.zeros_like(z)\n",
        "        for op in self.checker_transforms1:\n",
        "            z, delta_log_det = op.forward(z, conzf, reverse=False)\n",
        "            log_det += delta_log_det\n",
        "        z, log_det, conzf = self.squeeze(z), self.squeeze(log_det), self.squeeze(conzf)\n",
        "        for op in self.channel_transforms:\n",
        "            z, delta_log_det = op.forward(z, conzf, reverse=False)\n",
        "            log_det += delta_log_det\n",
        "        z, log_det, conzf = self.undo_squeeze(z), self.undo_squeeze(log_det), self.undo_squeeze(conzf)\n",
        "        for op in self.checker_transforms2:\n",
        "            z, delta_log_det = op.forward(z, conzf, reverse=False)\n",
        "            log_det += delta_log_det\n",
        "        return z, log_det\n",
        "        \n",
        "    def log_prob(self, x, condition):\n",
        "        z, log_det = self.f(x, condition)\n",
        "        return torch.sum(log_det, [1, 2, 3]) + torch.sum(self.prior.log_prob(z), [1, 2, 3])\n",
        "\n",
        "    def sample(self, num_samples, condition):\n",
        "        z = self.prior.sample([num_samples, self.x_channels, self.height, self.width])\n",
        "        return self.g(z, condition)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tgdH53G07mq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Solver(object):\n",
        "    def __init__(self, learning_rate=5e-4, n_epochs=128):\n",
        "        self.train_loader, self.val_loader = self.create_loaders()\n",
        "        self.log_interval = 100\n",
        "        self.n_epochs = n_epochs\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_batches_in_epoch = len(self.train_loader)\n",
        "\n",
        "    def build(self):\n",
        "      #change here for new input\n",
        "        self.flow = GlowConditional((3, 32, 32), 3).to(device)\n",
        "        self.optimizer = torch.optim.Adam(self.flow.parameters(), lr=self.learning_rate)\n",
        "\n",
        "    def create_loaders(self):\n",
        "        train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=False, drop_last = True)\n",
        "        test_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=False, drop_last = True)\n",
        "        return train_loader, test_loader\n",
        "\n",
        "    def preprocess(self, x, reverse=False, dequantize=True):\n",
        "        if reverse:\n",
        "            x = 1.0 / (1 + torch.exp(-x))\n",
        "            x -= 0.05\n",
        "            x /= 0.9\n",
        "            return x\n",
        "        else:\n",
        "            # dequantization\n",
        "            if dequantize:\n",
        "                x += torch.rand_like(x) / 2**5\n",
        "            max_value = x.max()\n",
        "            x /= max_value\n",
        "\n",
        "            # logit operation\n",
        "            x *= 0.9\n",
        "            x += 0.05\n",
        "            logit = torch.log(x) - torch.log(1.0 - x)\n",
        "            log_det = torch.nn.functional.softplus(logit) + torch.nn.functional.softplus(-logit) \\\n",
        "                      + torch.log(torch.tensor(0.9)) - torch.log(torch.tensor(max_value))\n",
        "            return logit, torch.mean(torch.sum(log_det, dim=(2, 3, 4)), dim=1)\n",
        "\n",
        "    def train(self):\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        for epoch_i in range(self.n_epochs):\n",
        "            epoch_i += 1\n",
        "\n",
        "            self.flow.train()\n",
        "            self.batch_loss_history = []\n",
        "\n",
        "            for batch_i, image in enumerate(tqdm(\n",
        "                    self.train_loader, desc='Batch', leave=False)):\n",
        "                \n",
        "                batch_i += 1\n",
        "                image = Variable(image).to(device)\n",
        "                logit_x, log_det = self.preprocess(image.float(), dequantize=True)\n",
        "                \n",
        "                for t in range(2, 5):\n",
        "                  \n",
        "                  log_prob = self.flow.log_prob(logit_x[:,t,:,:,:], logit_x[:,t-1,:,:,:])\n",
        "                  \n",
        "                  log_prob += log_det\n",
        "\n",
        "                batch_loss = -torch.mean(log_prob) / (3 * 32.0 * 32.0)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                self.optimizer.step()\n",
        "                batch_loss = float(batch_loss.data)\n",
        "                self.batch_loss_history.append(batch_loss)\n",
        "\n",
        "            epoch_loss = np.mean(self.batch_loss_history)\n",
        "            tqdm.write(f'Epoch {epoch_i} Loss: {epoch_loss:.2f}')\n",
        "\n",
        "            if epoch_i % 75 == 0:\n",
        "                self.save_model(\"GlowConditional{}.model\".format(str(epoch_i)))\n",
        "            train_losses.append(epoch_loss)\n",
        "            val_losses.append(self.get_loss(self.val_loader))\n",
        "            np.save(\"train_losses.npy\", np.array(train_losses))\n",
        "            np.save(\"val_losses.npy\", np.array(val_losses))\n",
        "\n",
        "        self.save_model(\"GlowConditional_final.model\")\n",
        "        return train_losses, val_losses\n",
        "\n",
        "    def get_loss(self, loader):\n",
        "        \"\"\"Compute error on provided data set\"\"\"\n",
        "        errors = []\n",
        "\n",
        "        # cuda.synchronize()\n",
        "        start = time.time()\n",
        "\n",
        "        self.flow.eval()\n",
        "\n",
        "        for image in loader:\n",
        "            with torch.no_grad():\n",
        "                image = image.to(device)\n",
        "                logit_x, log_det = self.preprocess(image.float(), dequantize=True)\n",
        "                for t in range(2, 5):\n",
        "                  \n",
        "                  log_prob = self.flow.log_prob(logit_x[:,t,:,:,:], logit_x[:,t-1,:,:,:])\n",
        "                  log_prob += log_det\n",
        "\n",
        "                loss = -torch.mean(log_prob) / (3 * 32.0 * 32.0)\n",
        "                error = float(loss.data)\n",
        "                errors.append(error)\n",
        "        \n",
        "        time_test = time.time() - start\n",
        "        log_string = f'Calc done! | It took {time_test:.1f}s | '\n",
        "        log_string += f'Loss: {np.mean(errors):.2f}'\n",
        "        tqdm.write(log_string)\n",
        "        return np.mean(errors)\n",
        "\n",
        "    def sample(self, num_samples):\n",
        "        with torch.no_grad():\n",
        "            raw_samples = self.flow.sample(num_samples).cpu()\n",
        "            samples = self.preprocess(raw_samples, reverse=True)\n",
        "            return samples.cpu().numpy()\n",
        "\n",
        "    def save_model(self, filename):\n",
        "        torch.save(self.flow, filename)\n",
        "\n",
        "    def load_model(self, filename):\n",
        "        self.flow = torch.load(filename, map_location=\"cpu\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK8FIY060881",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "889a3516f9124829baef79ecbabdb0c1",
            "ec8fc450aa5941e0a707f2c8f1b0041c",
            "374e40ad8f474ce5b2e574b01b71d3da",
            "86050815b7004d948dd62f6e06ea5865",
            "2fbad8ffc59b400ea9161559071e3564",
            "fcf8c4d8880d44afb069a91a6745642b",
            "022662d5a5c04232aa56ec900e72fecb",
            "374c59e73f084118873d8e1ae10e33f8"
          ]
        },
        "outputId": "69e97421-4573-4053-d21a-380956f752d6"
      },
      "source": [
        "solver = Solver(n_epochs=5, learning_rate=0.001)\n",
        "solver.build()\n",
        "train, val = solver.train()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "889a3516f9124829baef79ecbabdb0c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Batch', max=281.0, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d08199218acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-1af7d2f17d34>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                   \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                   \u001b[0mlog_prob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlog_det\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-9cd9c15f3ffd>\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, x, condition)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_det\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_det\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-9cd9c15f3ffd>\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, x, condition)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_det\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconzf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundo_squeeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundo_squeeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_det\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundo_squeeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconzf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecker_transforms2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_log_det\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconzf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0mlog_det\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdelta_log_det\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_det\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-9cd9c15f3ffd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, condition, reverse)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Takes the concatinating condition on the x.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mlog_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mlog_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_s\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_shift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-b851fba983a0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConditionalInvConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-b851fba983a0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-b851fba983a0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 416\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWrHikXZ0-pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=False, drop_last = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyE_xYDd1Azx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=next(iter(test_loader)).to(device)\n",
        "\n",
        "#Preprocess\n",
        "x_cont, _ = solver.preprocess(x, dequantize=True)\n",
        "\n",
        "#Sample from distribution\n",
        "prior = torch.distributions.Normal(torch.tensor(0.).to(device), torch.tensor(1.).to(device))\n",
        "z = prior.sample([batch_size, 3, 32, 32])\n",
        "\n",
        "t=2\n",
        "with torch.no_grad():\n",
        "  samples=solver.flow.g(z.to(device), x[:, t, :, :, :].to(device))\n",
        "\n",
        "# Preprocess samples\n",
        "samples=solver.preprocess(samples, dequantize=False, reverse=True)\n",
        "\n",
        "# Our true values\n",
        "conzre=solver.preprocess(x[:, t, :, :, :], dequantize=False, reverse=True)\n",
        "zre=solver.preprocess(x[:, t + 1, :, :, :], dequantize=False, reverse=True)\n",
        "zre2=solver.preprocess(x[:, t, :, :, :], dequantize=False, reverse=True)\n",
        "\n",
        "fig, axes = plt.subplots(3, 10 , figsize = (20,5))\n",
        "\n",
        "j=0\n",
        "k=0\n",
        "\n",
        "\n",
        "for i in range(0, 10):\n",
        "\n",
        "  axes[k*2, j].imshow(zre2[i].permute(1,2,0).detach().cpu().numpy())\n",
        "  axes[k*2, j].set_title('t, true')\n",
        "  axes[k*2, j].set_axis_off()\n",
        "  kk = conzre[i]/4*4\n",
        "  kk=samples[i]\n",
        "  axes[k*2+1, j].imshow(kk.permute(1,2,0).detach().cpu().numpy())\n",
        "  axes[k*2+1, j].set_title('t+1, sampled')\n",
        "  axes[k*2+1, j].set_axis_off()\n",
        "  \n",
        "  axes[k*2+2, j].imshow(zre[i].permute(1,2,0).detach().cpu().numpy())\n",
        "  axes[k*2+2, j].set_title('t+1, true')\n",
        "  axes[k*2+2, j].set_axis_off()\n",
        "  k+=1\n",
        "  if k*2 % 2 == 0:\n",
        "    j += 1\n",
        "    k = 0\n",
        "\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
